name: Benchmark

on:
  pull_request:
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.github/workflows/benchmark.yaml'
  push:
    branches: [main]
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.github/workflows/benchmark.yaml'
  workflow_dispatch:

permissions:
  contents: write
  pull-requests: write

jobs:
  benchmark:
    name: Run Benchmarks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          cache: true

      - name: Install dependencies
        run: |
          go mod download
          go install -mod=mod github.com/sivchari/govalid/cmd/govalid

      - name: Generate test code
        run: |
          cd test
          go generate

      - name: Run benchmarks
        run: |
          cd test/benchmark
          go test -bench=. -benchmem -benchtime=10s -count=10 | tee ../../benchmark-results.txt

      - name: Parse benchmark results
        id: parse
        run: |
          # Create a summary of benchmark results
          echo "## Benchmark Results" > benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "**Platform:** $(uname -s) $(uname -m)" >> benchmark-summary.md
          echo "**Go version:** $(go version | awk '{print $3}')" >> benchmark-summary.md
          echo "**Date:** $(date +%Y-%m-%d)" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          
          # Extract key benchmark comparisons
          echo "### Performance Comparison" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo "| Validator | govalid | go-playground | Improvement |" >> benchmark-summary.md
          echo "|-----------|---------|---------------|-------------|" >> benchmark-summary.md
          
          # Parse results for each validator type
          for validator in Required GT LT GTE LTE MaxLength MinLength MaxItems MinItems Enum Email UUID URL; do
            govalid_line=$(grep "BenchmarkGoValid${validator}-" benchmark-results.txt | tail -1)
            playground_line=$(grep "BenchmarkGoPlayground${validator}-" benchmark-results.txt | tail -1)
            
            if [ -n "$govalid_line" ] && [ -n "$playground_line" ]; then
              govalid_ns=$(echo "$govalid_line" | awk '{print $3}')
              playground_ns=$(echo "$playground_line" | awk '{print $3}')
              
              # Remove ns/op suffix for calculation
              govalid_num=$(echo "$govalid_ns" | sed 's/ns\/op//')
              playground_num=$(echo "$playground_ns" | sed 's/ns\/op//')
              
              # Calculate improvement factor
              if [ $(echo "$govalid_num > 0" | bc) -eq 1 ]; then
                improvement=$(echo "scale=1; $playground_num / $govalid_num" | bc)
                echo "| $validator | ${govalid_ns} | ${playground_ns} | ${improvement}x faster |" >> benchmark-summary.md
              fi
            fi
          done
          
          # Save raw results
          echo "" >> benchmark-summary.md
          echo "<details>" >> benchmark-summary.md
          echo "<summary>Raw Benchmark Results</summary>" >> benchmark-summary.md
          echo "" >> benchmark-summary.md
          echo '```' >> benchmark-summary.md
          cat benchmark-results.txt >> benchmark-summary.md
          echo '```' >> benchmark-summary.md
          echo "</details>" >> benchmark-summary.md
          
          # Set output for PR comment
          {
            echo 'summary<<EOF'
            cat benchmark-summary.md
            echo EOF
          } >> $GITHUB_OUTPUT

      - name: Comment PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const summary = `${{ steps.parse.outputs.summary }}`;
            
            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(comment => 
              comment.user.type === 'Bot' && 
              comment.body.includes('## Benchmark Results')
            );
            
            const body = `${summary}\n\n---\n*Automated benchmark report generated by GitHub Actions*`;
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body
              });
            }

      - name: Update README on main
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: |
          # Extract benchmark date and platform info
          BENCH_DATE=$(date +%Y-%m-%d)
          PLATFORM="$(uname -s) $(uname -r) $(uname -m)"
          GO_VERSION=$(go version | awk '{print $3}')
          
          # Create updated README content for test/benchmark
          cat > test/benchmark/README.md << EOF
# Benchmark Results

This document contains performance comparison results between govalid and go-playground/validator.

## Latest Results

**Benchmarked on:** ${BENCH_DATE}  
**Platform:** ${PLATFORM}  
**Go version:** ${GO_VERSION}

## Raw Benchmark Data

\`\`\`
EOF
          
          # Append raw benchmark results
          cat benchmark-results.txt >> test/benchmark/README.md
          
          # Close the code block and add footer
          cat >> test/benchmark/README.md << 'EOF'
```

## Performance Summary

EOF
          
          # Add the performance comparison table
          grep -A 100 "### Performance Comparison" benchmark-summary.md | grep -B 100 -E "^$|<details>" | head -n -1 | tail -n +4 >> test/benchmark/README.md
          
          # Run sync-benchmarks to update docs
          if [ -f scripts/sync-benchmarks.sh ]; then
            ./scripts/sync-benchmarks.sh
          fi
          
          # Configure git
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          
          # Check if there are changes
          if git diff --quiet; then
            echo "No changes to benchmark results"
          else
            git add test/benchmark/README.md
            git add docs/content/benchmarks.md docs/content/_index.md 2>/dev/null || true
            git commit -m "Update benchmark results

            Automated update from GitHub Actions
            Platform: ${PLATFORM}
            Date: ${BENCH_DATE}"
            git push
          fi

      - name: Upload benchmark results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results
          path: |
            benchmark-results.txt
            benchmark-summary.md
          retention-days: 30

  benchmark-compare:
    name: Compare with Base
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: benchmark
    
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4
        
      - name: Checkout base
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.base.sha }}
          path: base
          
      - name: Set up Go
        uses: actions/setup-go@v5
        with:
          go-version-file: 'go.mod'
          
      - name: Install benchstat
        run: go install golang.org/x/perf/cmd/benchstat@latest
        
      - name: Run base benchmarks
        run: |
          cd base
          go mod download
          go install -mod=mod github.com/sivchari/govalid/cmd/govalid
          cd test
          go generate
          cd benchmark
          go test -bench=. -benchmem -benchtime=10s -count=10 | tee ../../../base-benchmark.txt
          
      - name: Download current benchmarks
        uses: actions/download-artifact@v4
        with:
          name: benchmark-results
          
      - name: Compare benchmarks
        run: |
          benchstat base-benchmark.txt benchmark-results.txt > comparison.txt
          
          # Create comparison summary
          echo "## Benchmark Comparison (Base vs Current)" > comparison-summary.md
          echo "" >> comparison-summary.md
          echo '```' >> comparison-summary.md
          cat comparison.txt >> comparison-summary.md
          echo '```' >> comparison-summary.md
          
      - name: Comment comparison
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const comparison = fs.readFileSync('comparison-summary.md', 'utf8');
            
            const body = `${comparison}\n\n---\n*Benchmark comparison generated by benchstat*`;
            
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

